{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpYIBU4rQG4t"
      },
      "source": [
        "# Harry Potter and Word2Vec\n",
        "\n",
        "Word2vec is a method for embedding words into a small latent space which captures semantic meaning. The idea is to use a two layer (one hidden layer) fully connected neural network. The first layer of nodes (representing a one hot encoding of the index of some word $w$) connects to a small hidden layer which then connects to an output layer (representing a one hot encoding of the index of a word that appears near word $w$). Through training, we get the small hidden layer to hold the connection between words and their frequent neighbors.\n",
        "\n",
        "\n",
        "In this demo, we'll implement word2vec using all seven Harry Potter books as our corpus.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYiA684zOt4F"
      },
      "source": [
        "## Libraries\n",
        "\n",
        "As always, we rely on a lot of libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fq8pZAK27DDz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from matplotlib.patches import Rectangle\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "import numpy\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLHxU1tqOyvA"
      },
      "source": [
        "## Loading Text\n",
        "\n",
        "We load the text of Harry Potter from a website and preprocess it. In particular, we only want the chapters of the book and we make all words lowercase. Finally, we remove annoying characters like new lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wz2yu_chQG2z"
      },
      "outputs": [],
      "source": [
        "url1 = \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%201%20-%20The%20Philosopher's%20Stone.txt\"\n",
        "url2 = \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%202%20-%20The%20Chamber%20of%20Secrets.txt\"\n",
        "url3 = \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%203%20-%20The%20Prisoner%20of%20Azkaban.txt\"\n",
        "url4 = \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%204%20-%20The%20Goblet%20of%20Fire.txt\"\n",
        "url5 = \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%205%20-%20The%20Order%20of%20the%20Phoenix.txt\"\n",
        "url6 = \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%206%20-%20The%20Half%20Blood%20Prince.txt\"\n",
        "url7 = \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%207%20-%20The%20Deathly%20Hallows.txt\"\n",
        "\n",
        "def read_file(url, start_phrase, end_phrase, remove):\n",
        "  with urllib.request.urlopen(url) as webpage:\n",
        "    text = webpage.read().decode(\"utf8\")\n",
        "    start = text.index(start_phrase)\n",
        "    text = text[start:]\n",
        "    end = text.index(end_phrase)\n",
        "    text = text[:end]\n",
        "  return text.lower().replace('\\n', '').replace('Â¬','').replace(',','').replace('.','').replace(remove, '')\n",
        "\n",
        "text1 = read_file(url1, 'THE BOY WHO LIVED', 'Page | 348', 'Harry Potter and the Philosophers Stone - J.K. Rowling')\n",
        "text2 = read_file(url2, 'THE WORST BIRTHDAY', 'Page | 380', 'Harry Potter and the Chamber of Secrets - J.K. Rowling')\n",
        "text3 = read_file(url3, 'OWL POST', 'Page | 487', 'Harry Potter and the Prisoner of Azkaban - J.K. Rowling')\n",
        "text4 = read_file(url4, 'THE RIDDLE HOUSE', 'Page | 811', 'Harry Potter and the Goblet of Fire - J.K. Rowling')\n",
        "text5 = read_file(url5, 'DUDLEY DEMENTED', 'Page | 1108', 'Harry Potter and the Order of the Phoenix - J.K. Rowling')\n",
        "text6 = read_file(url6, 'THE OTHER MINISTER', 'Page | 730', 'Harry Potter and the Half Blood Prince - J.K. Rowling')\n",
        "text7 = read_file(url7, 'THE DARK LORD ASCENDING', 'Page | 856', 'Harry Potter and the Deathly Hallows - J.K. Rowling')\n",
        "\n",
        "text = text1 + text2 + text3 + text4 + text5 + text6 + text7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTehzSQtPGaZ"
      },
      "source": [
        "## Tokenizing\n",
        "\n",
        "Now we tokenize the text. That is, we turn the string into a list of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ITb7-sfhahjs"
      },
      "outputs": [],
      "source": [
        "def get_frequent(tokens, threshold=50):\n",
        "  frequency = {token : 0 for token in set(tokens)}\n",
        "  for token in tokens:\n",
        "    frequency[token] += 1\n",
        "  \n",
        "  frequent_tokens = []\n",
        "  for token in tokens:\n",
        "    if frequency[token] >= threshold:\n",
        "      frequent_tokens += [token]\n",
        "  \n",
        "  return frequent_tokens, len(set(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJEVyoWf8J73",
        "outputId": "0dad917f-c324-4835-f346-bfe26ae0771e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['the', 'boy', 'who', 'lived', 'mr', 'and', 'mrs', 'dursley', 'of', 'number', 'four', 'privet', 'drive', 'were', 'proud', 'to', 'say', 'that', 'they', 'were', 'perfectly', 'normal', 'thank', 'you', 'very', 'much', 'they', 'were', 'the', 'last', 'people', 'youd', 'expect', 'to', 'be', 'in', 'anything', 'strange', 'or', 'because', 'they', 'just', 'didnt', 'hold', 'with', 'such', 'mr', 'dursley', 'was', 'the', 'of', 'a', 'called', 'which', 'made', 'he', 'was', 'a', 'big', 'man', 'with', 'hardly', 'any', 'neck', 'although', 'he', 'did', 'have', 'a', 'very', 'large', 'mrs', 'dursley', 'was', 'thin', 'and', 'and', 'had', 'nearly', 'twice', 'the', 'usual', 'amount', 'of', 'neck', 'which', 'came', 'in', 'very', 'useful', 'as', 'she', 'spent', 'so', 'much', 'of', 'her', 'time', 'over', 'garden']\n"
          ]
        }
      ],
      "source": [
        "letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "def process_word(word):\n",
        "  return ''.join([letter for letter in word if letter in letters])\n",
        "tokens = [process_word(word) for word in text.split(' ')]\n",
        "\n",
        "tokens, num_tokens = get_frequent(tokens)\n",
        "print(tokens[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaRAaxLtNlk9",
        "outputId": "901530c6-f17a-446d-f6a5-2a1b1e67ba75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1036183 total tokens and 23182 unique tokens.\n"
          ]
        }
      ],
      "source": [
        "print(f'There are {len(tokens)} total tokens and {num_tokens} unique tokens.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY_eeC-gPcK8"
      },
      "source": [
        "Now we map from each word (token) to a unique index and back. We will use this for the one hot encoding of the word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eyw7PkfQ-iAb"
      },
      "outputs": [],
      "source": [
        "def mapping(tokens):\n",
        "  word_to_id = {}\n",
        "  id_to_word = {}\n",
        "\n",
        "  for i, token in enumerate(set(tokens)):\n",
        "    word_to_id[token] = i\n",
        "    id_to_word[i] = token\n",
        "  \n",
        "  return word_to_id, id_to_word\n",
        "\n",
        "WORD_TO_ID, ID_TO_WORD = mapping(tokens)\n",
        "num_tokens = len(set(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNu4q1OsPkG6"
      },
      "source": [
        "The next step is to get the dataset we will use. We do this by iterating through the tokens with a sliding window. For each word $w$, we look at its neighbors $u$ and add a data point $(w,u)$ where we need to predict $u$ on input $w$. For now, we store the data as indices to avoid carrying around a bunch of zeros in the one hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "g0jJf78x_bRh"
      },
      "outputs": [],
      "source": [
        "def convert(x):\n",
        "  return torch.tensor(np.asarray(x)).long()\n",
        "  \n",
        "def process(tokens, window=2, threshold=100):\n",
        "  frequency = {WORD_TO_ID[token]: 0 for token in set(tokens)}\n",
        "  X, y = [], []\n",
        "  for i in range(len(tokens)-1):\n",
        "    index_i = WORD_TO_ID[tokens[i]]\n",
        "    if frequency[index_i] < threshold:\n",
        "      for j in list(range(max(0,i-window), min(len(tokens), i+window+1))):\n",
        "        index_j = WORD_TO_ID[tokens[j]]\n",
        "        #if frequency[index_j] < threshold:\n",
        "        X += [index_i]\n",
        "        y += [index_j]\n",
        "        frequency[index_i] += 1\n",
        "        frequency[index_j] += 1\n",
        "  return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8s2bBqjXMO3"
      },
      "source": [
        "# Initialization\n",
        "\n",
        "Now we define the custom class we need so we can wrap the nice DataLoader function around our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "tTdzbQ9nWck0"
      },
      "outputs": [],
      "source": [
        "class DataSet(Dataset):\n",
        "  def __init__(self, tokens):\n",
        "    X,y = process(tokens)\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx] \n",
        "\n",
        "dataloader = DataLoader(DataSet(tokens), batch_size = 128, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "fI-iOCP0UivK"
      },
      "outputs": [],
      "source": [
        "class Word2Vec(nn.Module):\n",
        "  def __init__(self, num_tokens, embed_dim):\n",
        "    super(Word2Vec, self).__init__()\n",
        "    self.embedding = nn.Embedding(num_tokens, embed_dim)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.embedding(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "4g_v-qYm88dT"
      },
      "outputs": [],
      "source": [
        "def contrastive_loss(X_embedded, y_embedded):\n",
        "  batch_size = len(X_embedded)\n",
        "  gram = X_embedded @ y_embedded.T\n",
        "  difference = gram - torch.eye(batch_size).to(DEVICE)\n",
        "  return torch.sqrt(torch.square(difference).sum()/batch_size**2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W0DM6ZXQuXR"
      },
      "source": [
        "Finally, we're ready to initialize the architecture, loss, and optimizer. Notice the simplicity of the model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "E5bwwa809pd5"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "embed_dim = 64\n",
        "\n",
        "model = Word2Vec(num_tokens, embed_dim).to(DEVICE)\n",
        "\n",
        "losses = []\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-kIbSDIXGqF"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now let's train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlic9nmfD2tC",
        "outputId": "123a1f0e-9261-4829-c5c9-5168e3443588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 \t Loss: 5.720444679260254\n",
            "Epoch: 2 \t Loss: 4.175797462463379\n",
            "Epoch: 3 \t Loss: 2.2377748489379883\n",
            "Epoch: 4 \t Loss: 1.725404143333435\n",
            "Epoch: 5 \t Loss: 0.7257508039474487\n",
            "Epoch: 6 \t Loss: 0.7060225009918213\n",
            "Epoch: 7 \t Loss: 0.3669140040874481\n",
            "Epoch: 8 \t Loss: 0.2837032377719879\n",
            "Epoch: 9 \t Loss: 0.20808711647987366\n",
            "Epoch: 10 \t Loss: 0.19845540821552277\n",
            "Epoch: 11 \t Loss: 0.2003568857908249\n",
            "Epoch: 12 \t Loss: 0.20517590641975403\n",
            "Epoch: 13 \t Loss: 0.20199234783649445\n",
            "Epoch: 14 \t Loss: 0.19729004800319672\n",
            "Epoch: 15 \t Loss: 0.19830188155174255\n",
            "Epoch: 16 \t Loss: 0.1898644119501114\n",
            "Epoch: 17 \t Loss: 0.19841112196445465\n",
            "Epoch: 18 \t Loss: 0.20193296670913696\n",
            "Epoch: 19 \t Loss: 0.1928645223379135\n",
            "Epoch: 20 \t Loss: 0.191421240568161\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  total_loss = 0\n",
        "  for (X,y) in dataloader:\n",
        "    X = X.to(DEVICE)\n",
        "    y = y.to(DEVICE)\n",
        "    optimizer.zero_grad()\n",
        "    X_embedded = model(X)    \n",
        "    y_embedded = model(y)    \n",
        "    loss = contrastive_loss(X_embedded, y_embedded)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  losses += [total_loss/len(dataloader)]\n",
        "  print(f'Epoch: {epoch} \\t Loss: {loss}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x_ziNQHRAVt"
      },
      "source": [
        "## Exploring the Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70TH9Lcej1SF"
      },
      "source": [
        "What is the next word predicted?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB3kOnsbkJHA",
        "outputId": "5b7f5458-333e-40ab-cf52-c15cf10d367f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pitch\n",
            "quidditch\n",
            "practice\n",
            "game\n",
            "final\n",
            "cup\n",
            "playing\n",
            "play\n",
            "ended\n",
            "match\n"
          ]
        }
      ],
      "source": [
        "target = torch.tensor([WORD_TO_ID['quidditch']]).to(DEVICE)\n",
        "candidates = torch.tensor(list(ID_TO_WORD.keys())).to(DEVICE)\n",
        "candidates_embedded = model(candidates)\n",
        "target_embedded = model(target)\n",
        "\n",
        "similarities = candidates_embedded @ target_embedded.T\n",
        "_, indices = torch.topk(similarities.squeeze(), 10)\n",
        "\n",
        "for index in indices:\n",
        "  print(ID_TO_WORD[index.item()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oogwe4ErUFNd"
      },
      "source": [
        "To investigate the model, let's visualize the embeddings of the words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "eT_s4422gMUw",
        "outputId": "2f8f01bf-85f4-4c59-fbc7-e8598bf91e12"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 7 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def embed(word):\n",
        "  return model(torch.tensor(WORD_TO_ID[word]).to(DEVICE)).detach().cpu().numpy()\n",
        "\n",
        "words = ['slytherin', 'gryffindor', 'hufflepuff', 'ravenclaw',\n",
        "         'voldemort', 'snape', 'dumbledore']\n",
        "embeddings = [embed(word) for word in words] \n",
        "num_embed = len(embeddings)\n",
        "cmap = matplotlib.cm.coolwarm\n",
        "fig, axes = plt.subplots(num_embed, 1)\n",
        "norm = matplotlib.colors.Normalize(vmin=embeddings[0].min(), vmax=embeddings[0].max())\n",
        "for idx in range(num_embed):\n",
        "  ax = axes[idx]\n",
        "  embedding = embeddings[idx]\n",
        "  for i in range(embed_dim):\n",
        "    ax.add_patch(Rectangle((i/embed_dim, 0),.05,1, color=cmap(norm(embedding[i]))))\n",
        "  ax.text(1.02, .5, words[idx], fontsize=12)\n",
        "  ax.axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit ('3.10.0')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "6aea8d84a86a1280a34780710c5e478b9c6b3c016841b907182e7484363820b1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
